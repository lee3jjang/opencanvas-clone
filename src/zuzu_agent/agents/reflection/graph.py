from typing import cast

from langchain.chat_models import init_chat_model
from langchain_core.tools import tool
from langgraph.graph import MessagesState, StateGraph

from zuzu_agent.shared.utils import format_messages

REFLECT_SYSTEM_PROMPT = """You are an expert assistant, and writer. You are tasked with reflecting on the following conversation between a user and an AI assistant.
You are also provided with an 'artifact' the user and assistant worked together on to write. Artifacts can be code, creative writing, emails, or any other form of written content.

<artifact>
{artifact}
</artifact>

You have also previously generated the following reflections about the user. Your reflections are broken down into two categories:
1. Style Guidelines: These are the style guidelines you have generated for the user. Style guidelines can be anything from writing style, to code style, to design style.
  They should be general, and apply to the all the users work, including the conversation and artifact generated.
2. Content: These are general memories, facts, and insights you generate about the user. These can be anything from the users interests, to their goals, to their personality traits.
  Ensure you think carefully about what goes in here, as the assistant will use these when generating future responses or artifacts for the user.
  
<reflections>
{reflections}
</reflections>

Your job is to take all of the context and existing reflections and re-generate all. Use these guidelines when generating the new set of reflections:

<system-guidelines>
- Ensure your reflections are relevant to the conversation and artifact.
- Remove duplicate reflections, or combine multiple reflections into one if they are duplicating content.
- Do not remove reflections unless the conversation/artifact clearly demonstrates they should no longer be included.
  This does NOT mean remove reflections if you see no evidence of them in the conversation/artifact, but instead remove them if the user indicates they are no longer relevant.
- Keep the rules you list high signal-to-noise - don't include unnecessary reflections, but make sure the ones you do add are descriptive.
  This is very important. We do NOT want to confuse the assistant in future interactions by having lots and lots of rules and memories.
- Your reflections should be very descriptive and detailed, ensuring they are clear and will not be misinterpreted.
- Keep the total number of style and user facts low. It's better to have individual rules be more detailed, than to have many rules that are vague.
- Do NOT generate rules off of suspicions. Your rules should be based on cold hard facts from the conversation, and changes to the artifact the user has requested.
  You must be able to provide evidence and sources for each rule you generate if asked, so don't make assumptions.
- Content reflections should be based on the user's messages, not the generated artifacts. Ensure you follow this rule closely to ensure you do not record things generated by the assistant as facts about the user.
- Make sure the reflections are generated in Korean
</system-guidelines>

I'll reiterate one final time: ensure the reflections you generate are kept at a reasonable length, are descriptive, and are based on the conversation and artifact provided.

Finally, use the 'generate_reflections' tool to generate the new, full list of reflections."""

REFLECT_USER_PROMPT = """Here is my conversation:

{conversation}"""


@tool
def generate_reflections(
    style_rules: list[str],
    content: list[str],
) -> None:
    """Generate reflections based on the context provided.

    Args:
        style_rules (list[str]): The complete new list of style rules and guidelines.
        content (list[str]): The complete new list of memories/facts about the user.
    """


class ReflectionState(MessagesState):
    style_rules: list[str]
    content: list[str]


async def reflect(state: ReflectionState) -> dict:
    model = init_chat_model("anthropic:claude-3-5-haiku-latest").bind_tools(
        [generate_reflections]
    )

    formatted_system_prompt = REFLECT_SYSTEM_PROMPT.format(
        artifact="No artifact found,",
        reflections="No reflections found.",
    )
    formatted_user_prompt = REFLECT_USER_PROMPT.format(
        conversation=format_messages(state["messages"]),
    )

    result = await model.ainvoke(
        [
            ("system", formatted_system_prompt),
            ("user", formatted_user_prompt),
        ]
    )

    style_rules = cast(list[str], result.tool_calls[0]["args"]["style_rules"])
    content = cast(list[str], result.tool_calls[0]["args"]["content"])

    return {
        "style_rules": style_rules,
        "content": content,
    }


graph = (
    StateGraph(ReflectionState)
    .add_node(reflect)
    .set_entry_point("reflect")
    .compile()
    .with_config({"run_name": "reflection"})
)
